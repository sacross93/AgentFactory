import streamlit as st
import time
from utils import export_chat_history, save_feedback, check_ollama_server, wait_for_ollama_server
import json
from agents import final_answer_prompt 

def setup_page_config():
    """í˜ì´ì§€ ì„¤ì • ì´ˆê¸°í™”"""
    st.set_page_config(
        page_title="ì œí”Œëª° ì¢…í•© ìƒë‹´ ë´‡",
        page_icon="ğŸ”",
        layout="wide",
        initial_sidebar_state="expanded"
    )

def create_sidebar(memory):
    """ì‚¬ì´ë“œë°” UI ìƒì„±"""
    st.sidebar.title("ì„¤ì • ë° ì˜µì…˜")
    st.sidebar.markdown("---")
    
    # ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸° ë²„íŠ¼
    if st.sidebar.button("ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°"):
        memory.clear()
        st.session_state.messages = []
        st.session_state.process_logs = []
        st.rerun()
    
    # ê²€ìƒ‰ ì„¤ì • ì„¹ì…˜
    st.sidebar.markdown("## ê²€ìƒ‰ ì„¤ì •")
    max_searches = st.sidebar.slider("ìµœëŒ€ ê²€ìƒ‰ íšŸìˆ˜", min_value=1, max_value=10, value=5, step=1)
    show_search_process = st.sidebar.checkbox("ê²€ìƒ‰ ê³¼ì • ìë™ìœ¼ë¡œ ë³´ì—¬ì£¼ê¸°", value=False)
    
    # ëª¨ë¸ ì„¤ì • ì„¹ì…˜
    st.sidebar.markdown("## ëª¨ë¸ ì„¤ì •")
    model_options = ["gemma3:27b","exaone3.5:32b", "qwen2.5:32b", "deepseek-r1:32b"]
    selected_model = st.sidebar.selectbox("AI ëª¨ë¸ ì„ íƒ", model_options, index=0)
    
    # ëŒ€í™” ìŠ¤íƒ€ì¼ ì„¤ì •
    st.sidebar.markdown("## ëŒ€í™” ìŠ¤íƒ€ì¼")
    conversation_style = st.sidebar.selectbox(
        "ë‹µë³€ ìŠ¤íƒ€ì¼",
        ["í‘œì¤€", "ìƒì„¸í•œ ì„¤ëª…", "ê°„ê²°í•œ ìš”ì•½", "ì „ë¬¸ê°€ ìˆ˜ì¤€"],
        index=0
    )
    
    # ìì£¼ ë¬»ëŠ” ì§ˆë¬¸
    st.sidebar.markdown("## ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
    faq_questions = [
        "ì œí”Œëª°ì—ì„œ ê°€ì¥ ì¸ê¸°ìˆëŠ” CPUëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ê²Œì´ë° PC êµ¬ì„± ì¶”ì²œí•´ì£¼ì„¸ìš”",
        "ê·¸ë˜í”½ì¹´ë“œ ì—†ì´ ê²Œì„ì„ í•  ìˆ˜ ìˆë‚˜ìš”?",
        "RAMì€ ì–¼ë§ˆë‚˜ í•„ìš”í•œê°€ìš”?"
    ]
    selected_faq = st.sidebar.selectbox("ì§ˆë¬¸ ì„ íƒ", ["ì„ íƒí•˜ì„¸ìš”..."] + faq_questions)
    
    # ëŒ€í™” ë‚´ë³´ë‚´ê¸°/ê°€ì ¸ì˜¤ê¸° ê¸°ëŠ¥
    st.sidebar.markdown("## ëŒ€í™” ê´€ë¦¬")
    if st.sidebar.button("ëŒ€í™” ë‚´ë³´ë‚´ê¸°"):
        href = export_chat_history(st.session_state.messages)
        st.sidebar.markdown(href, unsafe_allow_html=True)

    uploaded_file = st.sidebar.file_uploader("ëŒ€í™” ê°€ì ¸ì˜¤ê¸°", type="json")
    if uploaded_file is not None:
        try:
            imported_messages = json.loads(uploaded_file.read())
            st.session_state.messages = imported_messages
            st.sidebar.success("ëŒ€í™” ë‚´ìš©ì„ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
            st.rerun()
        except Exception as e:
            st.sidebar.error(f"íŒŒì¼ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")

    # ì •ë³´ ì„¹ì…˜
    st.sidebar.markdown("---")
    st.sidebar.markdown("## ì •ë³´")
    st.sidebar.markdown("""
    ğŸ’¬ **ì œí”Œëª° ì¢…í•© ìƒë‹´ ë´‡**  
    ğŸ”„ ë²„ì „: 1.0.0  
    ğŸ‘¨â€ğŸ’» ê°œë°œ: AI ì—°êµ¬íŒ€ ê¹€ì§„ì˜ ì±…ì„
    """)

    # í”¼ë“œë°± ì„¹ì…˜
    st.sidebar.markdown("## í”¼ë“œë°±")
    feedback = st.sidebar.text_area("ì˜ê²¬ì´ë‚˜ ë²„ê·¸ ì œë³´", height=100)
    if st.sidebar.button("ì œì¶œ"):
        if save_feedback(feedback):
            st.sidebar.success("í”¼ë“œë°±ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
        else:
            st.sidebar.warning("í”¼ë“œë°±ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    return {
        "max_searches": max_searches,
        "show_search_process": show_search_process,
        "selected_model": selected_model,
        "conversation_style": conversation_style,
        "selected_faq": selected_faq
    }

def apply_custom_styles():
    """ì•±ì— ì‚¬ìš©ì ì •ì˜ ìŠ¤íƒ€ì¼ ì ìš©"""
    st.markdown("""
    <style>
    /* ë¡œê·¸ í•­ëª© ìŠ¤íƒ€ì¼ */
    .log-entry {
        padding: 8px;
        margin: 6px 0;
        border-radius: 4px;
        font-family: 'Courier New', monospace;
    }
    .log-info {
        background-color: #f0f8ff;
        border-left: 3px solid #0066cc;
    }
    .log-warning {
        background-color: #fff8e6;
        border-left: 3px solid #ffc107;
    }
    .log-error {
        background-color: #fff0f0;
        border-left: 3px solid #dc3545;
    }
    .log-success {
        background-color: #f0fff0;
        border-left: 3px solid #28a745;
    }
    
    /* ë¡œê·¸ ì»¨í…Œì´ë„ˆ */
    .log-container {
        max-height: 400px;
        overflow-y: auto;
        background-color: #f9f9f9;
        border-radius: 5px;
        padding: 10px;
        margin: 10px 0;
        border: 1px solid #ddd;
    }
    </style>
    """, unsafe_allow_html=True)

def create_chat_ui():
    """ì±„íŒ… UI ë° ì‚¬ìš©ì ì…ë ¥ ìƒì„±"""
    # ìŠ¤íƒ€ì¼ ì ìš©
    apply_custom_styles()
    
    # ì±„íŒ… UI ì»¨í…Œì´ë„ˆ
    chat_container = st.container()
    
    # ì±„íŒ… ë‚´ì—­ í‘œì‹œ (ì²˜ë¦¬ ì¤‘ì¸ í˜„ì¬ ì§ˆë¬¸ì€ ì œì™¸)
    with chat_container:
        for i, message in enumerate(st.session_state.messages):
            # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸ì´ë©´ í‘œì‹œí•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€)
            if (st.session_state.processing and 
                st.session_state.current_question and 
                message["role"] == "user" and 
                message["content"] == st.session_state.current_question and
                i == len(st.session_state.messages) - 1):
                continue
                
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸ í‘œì‹œ (ì²˜ë¦¬ ì¤‘ì¼ ë•Œë§Œ)
    if st.session_state.processing and st.session_state.current_question:
        with chat_container:
            with st.chat_message("user"):
                st.markdown(st.session_state.current_question)
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if st.session_state.processing:
        # ì²˜ë¦¬ ì¤‘ì¼ ë•ŒëŠ” ì…ë ¥ ë¹„í™œì„±í™”
        user_input = None
    else:
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        user_input = st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", key="user_input")
    
    return chat_container, user_input

def display_processing_status(chat_container, agent_system, question, memory, conversation_style):
    """ì²˜ë¦¬ ìƒíƒœ í‘œì‹œ ë° ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ
    progress_container = st.empty()
    
    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ í•¨ìˆ˜
    def update_progress(progress, status_text):
        """ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ë° ë¡œê·¸ ì €ì¥"""
        progress_container.progress(progress, text=status_text)
        
        # ë¡œê·¸ ì €ì¥ (ì„¸ì…˜ ìƒíƒœì— ì €ì¥)
        if "process_logs" not in st.session_state:
            st.session_state.process_logs = []
        
        # ì¤‘ë³µ ë¡œê·¸ ë°©ì§€
        if len(st.session_state.process_logs) == 0 or st.session_state.process_logs[-1] != status_text:
            st.session_state.process_logs.append(status_text)
            # ë””ë²„ê¹…ì„ ìœ„í•œ ì½˜ì†” ì¶œë ¥
            print(f"ì§„í–‰ ìƒí™©: {progress:.2f} - {status_text}")
    
    # í†µí•© ì—ì´ì „íŠ¸ ì‹¤í–‰
    try:
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        update_progress(0.1, "ğŸ” ì§ˆë¬¸ ë¶„ì„ ì¤‘...")
        
        # ì„¸ì…˜ ì´ˆê¸°í™” ë° ë¡œê·¸ ì €ì¥
        if "process_logs" not in st.session_state:
            st.session_state.process_logs = []
        st.session_state.process_logs = []  # ë¡œê·¸ ì´ˆê¸°í™”
        
        # í†µí•© ì—ì´ì „íŠ¸ ê°€ì ¸ì˜¤ê¸°
        integrated_agent = st.session_state.integrated_agent
        
        # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
        update_progress(0.3, "ğŸ§  ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ ì¤‘...")
        
        # í†µí•© ì—ì´ì „íŠ¸ ì‹¤í–‰
        result = integrated_agent.run_workflow(question, chat_history)
        
        # ë¡œê·¸ì— ìˆ˜ì§‘ëœ ì •ë³´ ì¶”ê°€
        collected_info = result.get("collected_information", [])
        for info in collected_info:
            update_progress(0.5, info)
        
        query_type = result.get("query_type", "web_search")
        
        # ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ìƒíƒœ ì—…ë°ì´íŠ¸
        query_type_display = {
            "web_search": "ğŸŒ ì›¹ ê²€ìƒ‰",
            "pc_compatibility": "ğŸ–¥ï¸ PC ë¶€í’ˆ í˜¸í™˜ì„± ë¶„ì„",
            "hybrid": "ğŸ”„ í†µí•© ë¶„ì„ (ì›¹ ê²€ìƒ‰ + í˜¸í™˜ì„± ë¶„ì„)"
        }
        
        update_progress(0.7, f"ğŸ’¡ {query_type_display.get(query_type, 'ì•Œ ìˆ˜ ì—†ìŒ')} ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘...")
        update_progress(0.9, "ğŸ“ ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘...")
        
        # ìµœì¢… ê²°ê³¼ ì¶”ì¶œ
        answer = result.get("answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì§„í–‰ ì™„ë£Œ
        update_progress(1.0, "âœ¨ ë‹µë³€ ìƒì„± ì™„ë£Œ!")
        time.sleep(0.5)  # ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ì ì‹œ í‘œì‹œ
        
        # ê²°ê³¼ í‘œì‹œ
        with chat_container.chat_message("assistant"):
            st.markdown(answer)
            
            # ì¿¼ë¦¬ íƒ€ì…ì— ë”°ë¥¸ í‘œì‹œ ì •ë³´
            query_type_display = {
                "web_search": "ğŸŒ ì›¹ ê²€ìƒ‰",
                "pc_compatibility": "ğŸ–¥ï¸ PC ë¶€í’ˆ í˜¸í™˜ì„± ë¶„ì„",
                "hybrid": "ğŸ”„ í†µí•© ë¶„ì„ (ì›¹ ê²€ìƒ‰ + í˜¸í™˜ì„± ë¶„ì„)"
            }
            
            with st.expander(f"ğŸ“Š ë‹µë³€ ìƒì„± ê³¼ì • ë³´ê¸° - {query_type_display.get(query_type, 'ì•Œ ìˆ˜ ì—†ìŒ')}", expanded=False):
                st.markdown(f"**ì²˜ë¦¬ ìœ í˜•:** {query_type_display.get(query_type, 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                
                # ìˆ˜ì§‘ëœ ëª¨ë“  ë¡œê·¸ í‘œì‹œ (ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜´)
                if "process_logs" in st.session_state and st.session_state.process_logs:
                    for log in st.session_state.process_logs:
                        st.write(log)
                
                # ì¶”ê°€ ì •ë³´: ìˆ˜ì§‘ëœ ì •ë³´ ì§ì ‘ í‘œì‹œ
                st.markdown("### ğŸ” ìˆ˜ì§‘ëœ ëª¨ë“  ì •ë³´")
                if collected_info:
                    for i, info in enumerate(collected_info):
                        st.write(f"{i+1}. {info}")
                else:
                    st.warning("âš ï¸ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
            memory.save_context({"question": question}, {"answer": answer})
            
            # ë©”ì‹œì§€ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": answer})
            
            # ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœë¡œ ì„¤ì •
            st.session_state.processing = False
            st.session_state.current_question = None
            
            return answer

    except Exception as e:
        error_msg = str(e)
        st.error(f"í†µí•© ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
        st.session_state.processing = False
        st.session_state.current_question = None
        return None

def display_server_status(container, check_interval=60):
    """ì„œë²„ ìƒíƒœ í‘œì‹œ"""
    if "last_server_check" not in st.session_state:
        st.session_state.last_server_check = 0
    
    current_time = time.time()
    if current_time - st.session_state.last_server_check > check_interval:
        st.session_state.server_status = check_ollama_server()
        st.session_state.last_server_check = current_time
    
    if st.session_state.server_status:
        container.success("ğŸŸ¢ AI ì„œë²„ ì—°ê²°ë¨")
    else:
        container.error("ğŸ”´ AI ì„œë²„ ì—°ê²° ëŠê¹€")
        if container.button("ì„œë²„ ì¬ì—°ê²° ì‹œë„"):
            if wait_for_ollama_server(max_retries=1):
                st.session_state.server_status = True
                container.success("âœ… ì„œë²„ ì—°ê²° ë³µêµ¬ë¨")
                time.sleep(1)
                st.rerun()
            else:
                container.error("âŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")