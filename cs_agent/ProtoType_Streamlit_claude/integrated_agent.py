from langchain_ollama import OllamaLLM
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.agents import AgentExecutor, create_react_agent
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Any, Optional
import json
import re
import logging
from datetime import datetime
import time
import traceback

# ê¸°ì¡´ ì—ì´ì „íŠ¸ ì„í¬íŠ¸
from agents import AgentSystem
from pc_check_agent import process_pc_compatibility_query
import config
from utils import search_cache

# ë¡œê¹… ì„¤ì •
from logging_config import get_logger

# ëª¨ë“ˆë³„ ë¡œê±° ê°€ì ¸ì˜¤ê¸°
logger = get_logger("IntegratedAgent")

# ìƒíƒœ ì •ì˜
class IntegratedAgentState(TypedDict):
    question: str
    chat_history: str
    query_type: str  # "web_search", "pc_compatibility", "hybrid"
    web_search_results: Optional[Dict[str, Any]]
    pc_compatibility_results: Optional[Dict[str, Any]]
    final_answer: Optional[str]
    errors: List[str]
    collected_information: List[str]  # ê²€ìƒ‰ ê³¼ì • ì •ë³´ ì¶”ê°€
    search_keywords: List[str]
    web_search_queries: List[str]

# ì§ˆë¬¸ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
query_classification_prompt = PromptTemplate.from_template("""
You are a query classification agent. Your task is to classify the user's question into one of the following categories:
1. "web_search" - Questions about software requirements, gaming performance, or general PC knowledge that require web search.
2. "pc_compatibility" - Questions about PC part compatibility, hardware specifications, or component recommendations.
3. "hybrid" - Questions that need both web search and PC compatibility analysis.

User question: {question}
Chat history: {chat_history}

Analyze the question carefully. If it mentions specific PC parts and their compatibility, it's likely "pc_compatibility".
If it's about software requirements or general knowledge, it's likely "web_search".
If it requires both hardware compatibility check and software performance information, it's "hybrid".

Examples:
- "ë¡¤ì„ í•  ìˆ˜ ìˆëŠ” ìµœì†Œ ì‚¬ì–‘ì´ ë­ì•¼?" -> "web_search" (This asks about minimum requirements for League of Legends)
- "AMD 5600Gì™€ í˜¸í™˜ë˜ëŠ” ë©”ì¸ë³´ë“œ ì¶”ì²œí•´ì¤˜" -> "pc_compatibility" (This asks about motherboard compatibility with AMD 5600G)
- "RTX 3070ìœ¼ë¡œ ë°°í‹€í•„ë“œ 2042ë¥¼ í’€ì˜µì…˜ìœ¼ë¡œ í•  ìˆ˜ ìˆì„ê¹Œ?" -> "hybrid" (This requires both hardware analysis and game requirements)

Return your classification as a JSON object with these fields:
- "query_type": one of "web_search", "pc_compatibility", or "hybrid"
- "reason": brief explanation for your classification

JSON:
""")

class IntegratedAgentGraph:
    def __init__(self, llm: OllamaLLM):
        """í†µí•© ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì´ˆê¸°í™” - ìƒíƒœ ê´€ë¦¬ ê°œì„ """
        self.llm = llm
        self.agent_system = AgentSystem(llm)
        self.graph = self._create_graph()
        
        # ê¸°ë³¸ ìƒíƒœ í…œí”Œë¦¿ - ëª¨ë“  ë…¸ë“œê°€ ì°¸ì¡°í•  ìˆ˜ ìˆëŠ” ì´ˆê¸° ìƒíƒœ ì •ì˜
        self.default_state = {
            "search_keywords": [],
            "web_search_queries": [],
            "errors": [],
            "collected_information": []
        }
        logger.info("í†µí•© ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _create_graph(self):
        # ê·¸ë˜í”„ ì •ì˜
        workflow = StateGraph(IntegratedAgentState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("classify_question", self.classify_question)
        workflow.add_node("web_search", self.web_search_node)
        workflow.add_node("pc_compatibility", self.pc_compatibility_node)
        workflow.add_node("hybrid_processing", self.hybrid_processing_node)
        workflow.add_node("generate_final_answer", self.generate_final_answer)
        workflow.add_node("generate_queries", self.generate_queries_node)
        workflow.add_node("hybrid_analysis", self.hybrid_analysis_node)
        
        # ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€
        workflow.add_conditional_edges(
            "classify_question",
            self.route_by_query_type,
            {
                "web_search": "web_search",
                "pc_compatibility": "pc_compatibility",
                "hybrid": "hybrid_processing"
            }
        )
        
        # ê²°ê³¼ í†µí•©ì„ ìœ„í•œ ì—£ì§€ ì¶”ê°€
        workflow.add_edge("web_search", "generate_final_answer")
        workflow.add_edge("pc_compatibility", "generate_final_answer")
        workflow.add_edge("hybrid_processing", "generate_final_answer")
        workflow.add_edge("generate_queries", "hybrid_analysis")
        workflow.add_edge("hybrid_analysis", "generate_final_answer")
        workflow.add_edge("generate_final_answer", END)
        
        # ì‹œì‘ì  ì§€ì •
        workflow.set_entry_point("classify_question")
        
        # ê·¸ë˜í”„ ì»´íŒŒì¼
        return workflow.compile()
    
    def classify_question(self, state: IntegratedAgentState) -> IntegratedAgentState:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ ë…¸ë“œ"""
        logger.info(f"ì§ˆë¬¸ ë¶„ë¥˜ ì‹œì‘: {state['question']}")
        
        # ë¡œê·¸ ì¶”ê°€
        state["collected_information"].append(f"ğŸ” ì§ˆë¬¸ ë¶„ì„: '{state['question']}'")
        
        try:
            response = self.llm.invoke(query_classification_prompt.format(
                question=state["question"],
                chat_history=state["chat_history"]
            ))
            
            # JSON ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group(0))
                query_type = result.get("query_type", "web_search")
                reason = result.get("reason", "No reason provided")
                
                # ë¡œê·¸ ì¶”ê°€
                state["collected_information"].append(f"ğŸ§  ì§ˆë¬¸ ìœ í˜•: {query_type} - {reason}")
                
                state["query_type"] = query_type
                logger.info(f"ì§ˆë¬¸ ë¶„ë¥˜ ì™„ë£Œ: {query_type} - {reason}")
                return state
            else:
                # ê¸°ë³¸ê°’ ì„¤ì •
                state["query_type"] = "web_search"
                state["collected_information"].append("âš ï¸ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’(web_search) ì‚¬ìš©")
                logger.warning("JSON ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ ìœ í˜•(web_search) ì‚¬ìš©")
                return state
        except Exception as e:
            # ì˜¤ë¥˜ ì²˜ë¦¬
            logger.error(f"ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            state["errors"].append(f"ì§ˆë¬¸ ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}")
            state["query_type"] = "web_search"
            state["collected_information"].append(f"âŒ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}")
            return state
    
    def route_by_query_type(self, state: IntegratedAgentState) -> str:
        """ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì²˜ë¦¬ ê²½ë¡œ ê²°ì •"""
        return state["query_type"]
    
    def web_search_node(self, state: IntegratedAgentState) -> IntegratedAgentState:
        """ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ì²˜ë¦¬ - ìºì‹± ë° ì¬ì‹œë„ ë¡œì§ ì¶”ê°€"""
        start_time = time.time()
        logger.info(f"ì›¹ ê²€ìƒ‰ ìˆ˜í–‰: {state['question']}")
        
        # ë¡œê·¸ ì¶”ê°€ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        state["collected_information"].append(
            f"ğŸŒ ì›¹ ê²€ìƒ‰ ì‹œì‘: '{state['question']}' ({time.strftime('%H:%M:%S')})"
        )
        
        # ìºì‹œì—ì„œ ê²°ê³¼ í™•ì¸
        cached_result = search_cache.get(state['question'])
        if cached_result:
            logger.info("ìºì‹œì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš©")
            state["collected_information"].append("ğŸ”„ ìºì‹œëœ ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš©")
            
            # ìºì‹œëœ ê²°ê³¼ì—ì„œ ìˆ˜ì§‘ ì •ë³´ ì¶”ì¶œ
            if "collected_information" in cached_result:
                for info in cached_result["collected_information"]:
                    state["collected_information"].append(info)
            
            state["web_search_results"] = cached_result
            return state
        
        # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        max_retries = 3
        retry_delay = 2  # ì´ˆ ë‹¨ìœ„
        
        for attempt in range(max_retries):
            try:
                # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë¡œê·¸
                state["collected_information"].append(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘... (ì‹œë„ {attempt+1}/{max_retries})")
                
                # ê¸°ì¡´ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í™œìš©
                result = self.agent_system.run_workflow(
                    state["question"], 
                    state["chat_history"]
                )
                
                # ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
                end_time = time.time()
                execution_time = end_time - start_time
                state["collected_information"].append(f"â±ï¸ ê²€ìƒ‰ ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")
                
                # ê²°ê³¼ ìºì‹±
                search_cache.set(state['question'], result)
                
                # ê²€ìƒ‰ ê³¼ì • ì •ë³´ ì¶”ê°€
                if "collected_information" in result:
                    for info in result["collected_information"]:
                        state["collected_information"].append(info)
                
                state["web_search_results"] = result
                logger.info("ì›¹ ê²€ìƒ‰ ì™„ë£Œ")
                state["collected_information"].append("âœ… ì›¹ ê²€ìƒ‰ ì™„ë£Œ")
                return state
                
            except Exception as e:
                error_msg = str(e)
                logger.error(f"ê²€ìƒ‰ ì‹œë„ {attempt+1}/{max_retries} ì‹¤íŒ¨: {error_msg}")
                state["collected_information"].append(f"âš ï¸ ê²€ìƒ‰ ì‹œë„ {attempt+1}/{max_retries} ì‹¤íŒ¨: {error_msg}")
                
                if attempt < max_retries - 1:
                    state["collected_information"].append(f"â³ {retry_delay}ì´ˆ í›„ ì¬ì‹œë„ ì¤‘...")
                    time.sleep(retry_delay)
                else:
                    state["errors"].append(f"ê²€ìƒ‰ ì‹¤íŒ¨: {error_msg}")
                    state["collected_information"].append("âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼, ê²€ìƒ‰ ì‹¤íŒ¨")
        
        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ
        state["web_search_results"] = {
            "final_answer": "ê²€ìƒ‰ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸ì„ ì‹œë„í•´ ë³´ì„¸ìš”.",
            "collected_information": state["collected_information"]
        }
        return state
    
    def pc_compatibility_node(self, state: IntegratedAgentState) -> IntegratedAgentState:
        """PC ë¶€í’ˆ í˜¸í™˜ì„± ë¶„ì„ - ë””ë²„ê¹… ê°•í™”"""
        start_time = time.time()
        # ë¡œê·¸ ì¶”ê°€ - íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
        timestamp = time.strftime('%H:%M:%S')
        state["collected_information"].append(f"ğŸ–¥ï¸ PC í˜¸í™˜ì„± ë¶„ì„ ì‹œì‘ ({timestamp})")
        logger.info(f"[{timestamp}] PC í˜¸í™˜ì„± ë¶„ì„: {state['question']}")
        
        try:
            # PC í˜¸í™˜ì„± ë¶„ì„ ì‹¤í–‰
            state["collected_information"].append(f"âš™ï¸ ë¶€í’ˆ ì •ë³´ ì¶”ì¶œ ì¤‘... ({timestamp})")
            
            # PC í˜¸í™˜ì„± ëª¨ë“ˆ ì§ì ‘ í˜¸ì¶œ ì‹œ ëª¨ë“  í•„ìš” ì •ë³´ ì „ë‹¬
            pc_input = {
                "question": state["question"],
                "search_keywords": state.get("search_keywords", []),
                "errors": []
            }
            
            # search_keywords í‚¤ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ê¸°ë³¸ê°’ ì„¤ì •
            try:
                from pc_check_agent import process_pc_compatibility_query
                
                # ëª¨ë“  í•„ìˆ˜ í•„ë“œê°€ ìˆëŠ” ì…ë ¥ ì „ë‹¬
                pc_result = process_pc_compatibility_query(
                    state["question"], 
                    input_state=pc_input  # í•„ìš”í•œ ëª¨ë“  ìƒíƒœ ë³€ìˆ˜ ì „ë‹¬
                )
                
                # ê²°ê³¼ ì €ì¥
                state["pc_compatibility_results"] = pc_result
                
                # ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë¡œê·¸ ì¶”ê°€
                if pc_result and pc_result.get("explanation"):
                    state["collected_information"].append(f"âœ… PC í˜¸í™˜ì„± ë¶„ì„ ê²°ê³¼ í™•ì¸: {len(pc_result.get('explanation', ''))}ì")
                else:
                    state["collected_information"].append("âš ï¸ PC í˜¸í™˜ì„± ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                
                return state
            except Exception as e:
                error_msg = f"PC í˜¸í™˜ì„± ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
                state["errors"].append(error_msg)
                state["collected_information"].append(f"âŒ {error_msg}")
                logger.error(error_msg)
                
                # ê¸°ë³¸ ê²°ê³¼ ìƒì„±
                state["pc_compatibility_results"] = {
                    "explanation": "PC í˜¸í™˜ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                }
                return state
        except Exception as e:
            error_msg = str(e)
            timestamp_error = time.strftime('%H:%M:%S')
            logger.error(f"[{timestamp_error}] PC í˜¸í™˜ì„± ë¶„ì„ ì˜¤ë¥˜: {error_msg}")
            state["collected_information"].append(f"âŒ í˜¸í™˜ì„± ë¶„ì„ ì˜¤ë¥˜ ({timestamp_error}): {error_msg}")
            state["errors"].append(f"PC í˜¸í™˜ì„± ë¶„ì„ ì˜¤ë¥˜: {error_msg}")
            return state
    
    def hybrid_processing_node(self, state: IntegratedAgentState) -> IntegratedAgentState:
        """ì›¹ ê²€ìƒ‰ê³¼ í˜¸í™˜ì„± ê²€ì‚¬ ëª¨ë‘ ìˆ˜í–‰ - ì™„ì „íˆ ë…ë¦½ì ì¸ ì‹¤í–‰"""
        logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ìˆ˜í–‰: {state['question']}")
        
        try:
            # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ - ë…ë¦½ì ì¸ ìƒíƒœë¡œ ì‹¤í–‰
            web_search_state = {
                "question": state["question"],
                "chat_history": state["chat_history"],
                "query_type": "web_search",
                "errors": [],
                "collected_information": []
            }
            
            state["collected_information"].append("ğŸŒ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
            
            try:
                # ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì§ì ‘ ì‹¤í–‰
                web_result = self.agent_system.run_workflow(
                    state["question"], 
                    state["chat_history"]
                )
                state["web_search_results"] = web_result
                state["collected_information"].append("âœ… ì›¹ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸")
            except Exception as web_error:
                error_msg = f"ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {str(web_error)}"
                state["errors"].append(error_msg)
                state["collected_information"].append(f"âŒ {error_msg}")
                logger.error(error_msg)
            
            # PC í˜¸í™˜ì„± ê²€ì‚¬ - ì™„ì „íˆ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰
            state["collected_information"].append("ğŸ–¥ï¸ PC í˜¸í™˜ì„± ê²€ì‚¬ ëª¨ë“ˆ í˜¸ì¶œ ì¤‘...")
            
            try:
                # ëª¨ë“  ì˜ì¡´ì„±ì„ ì œê±°í•˜ê³  ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰
                import pc_check_agent
                from importlib import reload
                
                # ëª¨ë“ˆ ë¦¬ë¡œë“œë¡œ ì´ì „ ìƒíƒœì— ì˜í–¥ì„ ë°›ì§€ ì•Šê²Œ í•¨
                reload(pc_check_agent)
                
                # search_keywords ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ì§ì ‘ ì§ˆë¬¸ë§Œ ì „ë‹¬
                pc_result = pc_check_agent.process_pc_compatibility_query(state["question"])
                
                # ê²°ê³¼ ë¡œê¹…
                if pc_result and pc_result.get("explanation"):
                    state["collected_information"].append(f"âœ… PC í˜¸í™˜ì„± ë¶„ì„ ê²°ê³¼ í™•ì¸: {len(pc_result.get('explanation', ''))}ì")
                else:
                    state["collected_information"].append("âš ï¸ PC í˜¸í™˜ì„± ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                    
                state["pc_compatibility_results"] = pc_result
            except Exception as pc_error:
                # ì˜¤ë¥˜ ìƒì„¸ ì •ë³´ ìº¡ì²˜
                import traceback
                error_msg = f"PC í˜¸í™˜ì„± ê²€ì‚¬ ì˜¤ë¥˜: {str(pc_error)}"
                trace_msg = traceback.format_exc()
                state["errors"].append(error_msg)
                state["collected_information"].append(f"âŒ {error_msg}")
                logger.error(f"{error_msg}\n{trace_msg}")
                
                # ê¸°ë³¸ ê²°ê³¼ ìƒì„±
                state["pc_compatibility_results"] = {
                    "explanation": "PC í˜¸í™˜ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                }
            
            logger.info("í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ì™„ë£Œ")
            return state
            
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            state["errors"].append(f"í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return state
    
    def generate_queries_node(self, state: IntegratedAgentState) -> IntegratedAgentState:
        """ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë…¸ë“œ - ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”"""
        try:
            logger.info(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹œì‘: {state['question']}")
            
            # ì´ˆê¸° ìƒíƒœ í™•ì¸ ë° ì´ˆê¸°í™” - ëˆ„ë½ëœ ê²½ìš°ë¥¼ ëŒ€ë¹„
            if 'search_keywords' not in state:
                # ê²€ìƒ‰ í‚¤ì›Œë“œ ì´ˆê¸°í™”
                state['search_keywords'] = []
                logger.warning("'search_keywords' í‚¤ê°€ ìƒíƒœì— ì—†ì–´ì„œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
            
            # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            keyword_extraction_prompt = PromptTemplate.from_template("""
            ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ì¤‘ìš”í•œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
            ì§ˆë¬¸: {question}
            
            ìµœëŒ€ 5ê°œì˜ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ê³ , ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ëª©ë¡ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
            ê° í‚¤ì›Œë“œëŠ” 1-3ë‹¨ì–´ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
            """)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ ì²´ì¸
            keyword_extraction_chain = keyword_extraction_prompt | self.llm | StrOutputParser()
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰
            keywords_result = keyword_extraction_chain.invoke({"question": state["question"]})
            
            # ë¡œê·¸ ì¶”ê°€
            state["collected_information"].append(f"ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords_result}")
            
            # í‚¤ì›Œë“œ ì •ë¦¬ ë° ì €ì¥
            keywords = [kw.strip() for kw in keywords_result.split(",")]
            state["search_keywords"] = keywords
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë¡œì§
            search_query_prompt = PromptTemplate.from_template("""
            ë‹¤ìŒ ì§ˆë¬¸ê³¼ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ íš¨ê³¼ì ì¸ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ 2-3ê°œ ìƒì„±í•´ì£¼ì„¸ìš”:
            ì§ˆë¬¸: {question}
            í‚¤ì›Œë“œ: {keywords}
            
            ê° ì¿¼ë¦¬ëŠ” ì›¹ ê²€ìƒ‰ ì—”ì§„ì—ì„œ ì¢‹ì€ ê²°ê³¼ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆë„ë¡ ê°„ê²°í•˜ê³  ëª…í™•í•´ì•¼ í•©ë‹ˆë‹¤.
            ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ëª©ë¡ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
            """)
            
            # ì¿¼ë¦¬ ìƒì„± ì²´ì¸
            search_query_chain = search_query_prompt | self.llm | StrOutputParser()
            
            # ì¿¼ë¦¬ ìƒì„± ì‹¤í–‰
            query_result = search_query_chain.invoke({
                "question": state["question"],
                "keywords": ", ".join(state["search_keywords"])
            })
            
            # ë¡œê·¸ ì¶”ê°€
            state["collected_information"].append(f"ğŸ” ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {query_result}")
            
            # ì¿¼ë¦¬ ì •ë¦¬ ë° ì €ì¥
            queries = [q.strip() for q in query_result.split(",")]
            
            # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ìš© ì¿¼ë¦¬ ì €ì¥
            state["web_search_queries"] = queries[:3]  # ìµœëŒ€ 3ê°œ ì¿¼ë¦¬ë§Œ ì‚¬ìš©
            
            return state
        except Exception as e:
            error_msg = f"ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            stack_trace = traceback.format_exc()
            logger.error(f"{error_msg}\n{stack_trace}")
            
            # ì˜¤ë¥˜ ì •ë³´ ì €ì¥ ë° ê¸°ë³¸ê°’ ì„¤ì •
            state["errors"].append(error_msg)
            state["collected_information"].append(f"âŒ {error_msg}")
            
            # ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ ì„¤ì • (ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜)
            if "web_search_queries" not in state or not state["web_search_queries"]:
                state["web_search_queries"] = [state["question"]]  # ê¸°ë³¸ ì¿¼ë¦¬ë¡œ ì›ë³¸ ì§ˆë¬¸ ì‚¬ìš©
                state["collected_information"].append("âš ï¸ ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
            
            return state

    def hybrid_analysis_node(self, state: IntegratedAgentState) -> IntegratedAgentState:
        """í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ë…¸ë“œ - ì˜¤ë¥˜ ëŒ€ì‘ ê°•í™”"""
        start_time = time.time()
        try:
            timestamp = time.strftime('%H:%M:%S')
            state["collected_information"].append(f"ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œì‘ ({timestamp})")
            logger.info(f"[{timestamp}] í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„: {state['question']}")
            
            # ì›¹ ê²€ìƒ‰ ë¶€ë¶„
            try:
                # ê²€ìƒ‰ í‚¤ì›Œë“œ í™•ì¸ ë° ë³µêµ¬
                if "search_keywords" not in state or not state["search_keywords"]:
                    # ëˆ„ë½ëœ ê²½ìš° ë³µêµ¬ ì‹œë„
                    state = self.generate_queries_node(state)
                
                # ì›¹ ê²€ìƒ‰ ì‹¤í–‰
                state["collected_information"].append(f"ğŸŒ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘... ({time.strftime('%H:%M:%S')})")
                state = self.web_search_node(state)
            except Exception as e:
                error_msg = f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì¤‘ ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
                state["errors"].append(error_msg)
                state["collected_information"].append(f"âŒ {error_msg}")
                logger.error(error_msg)
            
            # PC í˜¸í™˜ì„± ë¶„ì„ ë¶€ë¶„
            try:
                state["collected_information"].append(f"ğŸ–¥ï¸ PC í˜¸í™˜ì„± ë¶„ì„ ì¤‘... ({time.strftime('%H:%M:%S')})")
                state = self.pc_compatibility_node(state)
            except Exception as e:
                error_msg = f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì¤‘ í˜¸í™˜ì„± ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
                state["errors"].append(error_msg)
                state["collected_information"].append(f"âŒ {error_msg}")
                logger.error(error_msg)
            
            # ìµœì¢… ë‹µë³€ ìƒì„±
            state["collected_information"].append(f"ğŸ“ í†µí•© ë¶„ì„ ê²°ê³¼ ì¢…í•© ì¤‘... ({time.strftime('%H:%M:%S')})")
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            end_time = time.time()
            duration = end_time - start_time
            state["collected_information"].append(f"â±ï¸ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì†Œìš” ì‹œê°„: {duration:.2f}ì´ˆ")
            
            return state
        except Exception as e:
            error_msg = f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            logger.error(error_msg)
            state["errors"].append(error_msg)
            state["collected_information"].append(f"âŒ {error_msg}")
            
            # ì„±ëŠ¥ ê´€ë ¨ ì •ë³´ ì¶”ê°€
            end_time = time.time()
            duration = end_time - start_time
            state["collected_information"].append(f"â±ï¸ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹¤íŒ¨ ì‹œê°„: {duration:.2f}ì´ˆ")
            
            return state
    
    def generate_final_answer(self, state: IntegratedAgentState) -> IntegratedAgentState:
        """ìµœì¢… ê²°ê³¼ ìƒì„± - ì¤‘ë³µ ë°©ì§€ ê°•í™”"""
        logger.info(f"ìµœì¢… ë‹µë³€ ìƒì„± ì‹œì‘")
        
        query_type = state["query_type"]
        question = state["question"]
        
        try:
            # ê²€ìƒ‰ ê²°ê³¼ì™€ í˜¸í™˜ì„± ê²°ê³¼ ì¶”ì¶œ
            web_results = state.get("web_search_results", None)
            pc_results = state.get("pc_compatibility_results", None)
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ Noneì¸ ê²½ìš° ì²˜ë¦¬
            web_answer = "ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            if web_results is not None:
                web_answer = web_results.get("final_answer", web_answer)
            
            # PC í˜¸í™˜ì„± ê²°ê³¼ê°€ Noneì¸ ê²½ìš° ì²˜ë¦¬
            pc_explanation = "PC ë¶€í’ˆ í˜¸í™˜ì„± ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            if pc_results is not None:
                pc_explanation = pc_results.get("explanation", pc_explanation)
            
            # ì¿¼ë¦¬ ìœ í˜•ì— ë”°ë¼ ì ì ˆí•œ ì‘ë‹µ ìƒì„±
            if query_type == "web_search":
                final_answer = web_answer
            elif query_type == "pc_compatibility":
                final_answer = pc_explanation
            elif query_type == "hybrid":
                # ë‘ ê²°ê³¼ í†µí•© (ë” ê°•ë ¥í•œ ì¤‘ë³µ ë°©ì§€)
                integration_prompt = PromptTemplate.from_template("""
                ì‚¬ìš©ì ì§ˆë¬¸: {question}
                
                ì›¹ ê²€ìƒ‰ ê²°ê³¼:
                {web_results}
                
                PC ë¶€í’ˆ í˜¸í™˜ì„± ë¶„ì„:
                {pc_results}
                
                ìœ„ ë‘ ê°€ì§€ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ì¢…í•©ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
                
                [ì¤‘ìš”]
                1. ë‹µë³€ì€ ë°˜ë“œì‹œ ì¤‘ë³µ ì—†ì´ í•œ ë²ˆë§Œ ì‘ì„±í•˜ì„¸ìš”. 
                2. ë™ì¼í•œ ë‚´ìš©ì´ë‚˜ ë‹¨ë½ì„ ë‘ ë²ˆ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.
                3. ë‹µë³€ì€ 4-5ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•˜ê³ , ì´ 250ë‹¨ì–´ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
                4. ë‹µë³€ì— ì œëª©ì´ë‚˜ í—¤ë”ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
                """)
                
                try:
                    # ì •í™•í•œ ì‘ë‹µ í¬ë§·ì„ ì§€ì •í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
                    final_answer = self.llm.invoke(integration_prompt.format(
                        question=question,
                        web_results=web_answer,
                        pc_results=pc_explanation
                    ))
                    
                    # ì¤‘ë³µ ê²€ì‚¬ ë° ìˆ˜ì •
                    final_answer = self._check_and_fix_duplicates(final_answer)
                except Exception as int_error:
                    logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(int_error)}")
                    # ë‹¨ìˆœíˆ ë‘ ë‹µë³€ì„ ì—°ê²°í•˜ëŠ” ë°±ì—… ë°©ë²•
                    final_answer = f"ì›¹ ê²€ìƒ‰ ê²°ê³¼: {web_answer}\n\nPC í˜¸í™˜ì„± ë¶„ì„: {pc_explanation}"
            else:
                final_answer = "ì§ˆë¬¸ ìœ í˜•ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            state["final_answer"] = final_answer
            logger.info("ìµœì¢… ë‹µë³€ ìƒì„± ì™„ë£Œ")
            return state
            
        except Exception as e:
            logger.error(f"ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            state["errors"].append(f"ìµœì¢… ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            state["final_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            return state
        
    def _check_and_fix_duplicates(self, text):
        """ë‹µë³€ ì¤‘ë³µ ê²€ì‚¬ ë° ìˆ˜ì •"""
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        
        if len(paragraphs) <= 1:
            return text
        
        # ì¤‘ë³µ ë‹¨ë½ ì œê±°
        unique_paragraphs = []
        seen_content = set()
        
        for para in paragraphs:
            # ê°„ë‹¨í•œ ì§€ë¬¸(fingerprint) ìƒì„± - ë¬¸ë‹¨ì˜ ì²˜ìŒ 50ìì™€ ë§ˆì§€ë§‰ 50ì
            if len(para) > 100:
                fingerprint = para[:50] + para[-50:]
            else:
                fingerprint = para
            
            if fingerprint not in seen_content:
                unique_paragraphs.append(para)
                seen_content.add(fingerprint)
        
        # ê²°ê³¼ ë°˜í™˜
        return '\n\n'.join(unique_paragraphs)
    
    def run_workflow(self, question: str, chat_history: str) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ - ìƒíƒœ ì´ˆê¸°í™” ê°œì„ """
        logger.info(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰: {question}")
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì • - ëª¨ë“  í•„ìˆ˜ í‚¤ë¥¼ ë¯¸ë¦¬ ì •ì˜í•˜ì—¬ ëˆ„ë½ ë°©ì§€
        inputs = {
            "question": question,
            "chat_history": chat_history,
            "query_type": "",
            "web_search_results": None,
            "pc_compatibility_results": None,
            "final_answer": None,
            "errors": [],
            "collected_information": [],
            "search_keywords": [],
            "web_search_queries": []
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result = self.graph.invoke(inputs)
        
        # ê²°ê³¼ ë¡œê¹…
        if result["final_answer"]:
            logger.info(f"ì›Œí¬í”Œë¡œìš° ì™„ë£Œ - ë‹µë³€ ê¸¸ì´: {len(result['final_answer'])}")
        else:
            logger.warning("ì›Œí¬í”Œë¡œìš° ì™„ë£Œ - ë‹µë³€ ì—†ìŒ")
        
        # ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "answer": result.get("final_answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
            "query_type": result.get("query_type", "unknown"),
            "collected_information": result.get("collected_information", []),
            "errors": result.get("errors", [])
        }

# í†µí•© ì—ì´ì „íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜
def create_integrated_agent(llm=None):
    """í†µí•© ì—ì´ì „íŠ¸ ìƒì„±"""
    if llm is None:
        # ê¸°ë³¸ LLM ì„¤ì •
        llm = OllamaLLM(
            model=config.DEFAULT_MODEL,
            base_url=config.OLLAMA_BASE_URL
        )
    
    return IntegratedAgentGraph(llm) 