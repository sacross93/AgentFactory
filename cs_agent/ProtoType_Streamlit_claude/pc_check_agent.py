from langchain_ollama import OllamaLLM
from langchain_community.tools import DuckDuckGoSearchResults
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain.agents import AgentExecutor, create_react_agent
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Any, Optional
import json
import duckdb
import pandas as pd
import re
import os
from logging_config import get_logger

# Ollama ëª¨ë¸ ì´ˆê¸°í™” - ì˜¨ë„ ì¶”ê°€
llm = OllamaLLM(
    model="qwen2.5-coder:32b",
    base_url="http://192.168.110.102:11434",
    temperature=0.1  # ë‚®ì€ ì˜¨ë„ë¡œ ë” ì¼ê´€ëœ ì‘ë‹µ ìœ ë„
)
DB_PATH = '/home/wlsdud022/AgentFactory/cs_agent/db/pc_parts.db'

# ìƒíƒœ ì •ì˜
class PCCompatibilityState(TypedDict):
    question: str
    search_keywords: List[str]
    part_types: List[str]
    queries: Dict[str, str]
    results: Dict[str, Any]
    errors: List[str]
    final_result: Optional[Dict[str, Any]]
    analysis_logs: List[str]
    components: List[str]
    query_results: Dict[str, List[Dict[str, Any]]]
    compatibility_results: Dict[str, Any]

# ë°ì´í„°ë² ì´ìŠ¤ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
def get_db_samples():
    samples = {}
    try:
        # í•¨ìˆ˜ ë‚´ì—ì„œ ì—°ê²° ìƒì„±
        with duckdb.connect(DB_PATH, read_only=True) as conn:
            # CPU ìƒ˜í”Œ
            samples['cpu'] = conn.execute("SELECT model_name FROM cpu LIMIT 5").fetchall()
            # GPU ìƒ˜í”Œ
            samples['gpu'] = conn.execute("SELECT model_name FROM gpu LIMIT 5").fetchall()
            # ë§ˆë”ë³´ë“œ ìƒ˜í”Œ
            samples['motherboard'] = conn.execute("SELECT model_name FROM motherboard LIMIT 5").fetchall()
            
            # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            for key in samples:
                samples[key] = [item[0] for item in samples[key]]
    except Exception as e:
        print(f"Error getting samples: {str(e)}")
    
    return samples

# ë°ì´í„°ë² ì´ìŠ¤ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
db_samples = get_db_samples()

# ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_db_schema():
    schema_info = {}
    
    # í•¨ìˆ˜ ë‚´ì—ì„œ ì—°ê²° ìƒì„±
    with duckdb.connect(DB_PATH, read_only=True) as conn:
        tables = conn.execute("SHOW TABLES").fetchall()
        
        for table in tables:
            table_name = table[0]
            columns = conn.execute(f"PRAGMA table_info({table_name})").fetchall()
            schema_info[table_name] = [col[1] for col in columns]
    
    return schema_info

# ìŠ¤í‚¤ë§ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
db_schema = get_db_schema()

# í…Œì´ë¸” ì´ë¦„ ë§¤í•‘ í™•ì¥
table_mapping = {
    "cpu_support": "cpu_mb_compatibility",
    "motherboard_compatibility": "cpu_mb_compatibility",
    "cpu_motherboard": "cpu_mb_compatibility",
    "mb": "motherboard",
    "mainboard": "motherboard",
    "case": "case_chassis",
    "case_product": "case_chassis",
    "cooler": "cpu_cooler",
    "psu": "power_supply",
    "ram": "memory",
    "gpu_compatibility": "gpu_case_compatibility",
    "cpu_compatibility": "cpu_mb_compatibility",
    "gpu_mb_compatibility": "mb_gpu_compatibility",
    "memory_mb_compatibility": "mb_memory_compatibility",
    "cpu_cooler_compatibility": "cpu_cooler_compatibility",
    "psu_compatibility": "psu_case_compatibility",
    "storage_compatibility": "mb_storage_compatibility"
}

# ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
schema_str = "Database Schema:\n"
for table, columns in db_schema.items():
    schema_str += f"Table: {table}\n"
    schema_str += f"Columns: {', '.join(columns)}\n\n"

# ëª¨ë“ˆë³„ ë¡œê±° ê°€ì ¸ì˜¤ê¸°
logger = get_logger("PCCheckAgent")

# 1. ì§ˆë¬¸ ë¶„ì„ ë…¸ë“œ
def analyze_question(state: PCCompatibilityState) -> PCCompatibilityState:
    """ì§ˆë¬¸ ë¶„ì„ ë…¸ë“œ"""
    logger.info(f"PC í˜¸í™˜ì„± ì§ˆë¬¸ ë¶„ì„ ì‹œì‘: {state['question']}")
    
    # ë¶„ì„ ê³¼ì • ë¡œê·¸ì— ì¶”ê°€
    state["analysis_logs"].append(f"ğŸ” ì§ˆë¬¸ ë¶„ì„: '{state['question']}'")
    
    try:
        # ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰
        response = llm.invoke(question_analysis_prompt.format(
            question=state["question"]
        ))
        
        # JSON ì¶”ì¶œ
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group(0))
            state["components"] = result.get("components", [])
            state["analysis_logs"].append(f"âœ… ë¶„ì„ëœ ë¶€í’ˆ: {', '.join(state['components'])}")
            return state
        else:
            state["errors"].append("ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼ì—ì„œ JSONì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return state
    except Exception as e:
        state["errors"].append(f"ì§ˆë¬¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return state

# 2. ì¿¼ë¦¬ ìƒì„± ë…¸ë“œ
def generate_queries(state: PCCompatibilityState) -> PCCompatibilityState:
    """ë¶€í’ˆ ìœ í˜• ë° í‚¤ì›Œë“œì— ê¸°ë°˜í•œ SQL ì¿¼ë¦¬ ìƒì„±"""
    logger.info("Starting node: generate_queries")
    
    try:
        # 'search_keywords' í‚¤ê°€ ì—†ëŠ” ê²½ìš° ì´ˆê¸°í™”
        if "search_keywords" not in state:
            state["search_keywords"] = []
            logger.warning("stateì— 'search_keywords' í‚¤ê°€ ì—†ì–´ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤")
        
        search_keywords = state["search_keywords"]
        
        question = state["question"]
        part_types = state["part_types"]
        
        # í•¨ìˆ˜ ì‹œì‘ì‹œ ìƒíƒœ ë¡œê¹…
        logger.debug(f"===== STATE (generate_queries_start) =====")
        logger.debug(f"question: {question}")
        logger.debug(f"search_keywords: {search_keywords}")
        logger.debug(f"part_types: {part_types}")
        
        # í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
        if not search_keywords:
            state["errors"].append("No search keywords found in the question.")
            return state
        
        # í‚¤ì›Œë“œ ì²˜ë¦¬ ê°œì„  - ë” ìœ ì—°í•œ ê²€ìƒ‰ íŒ¨í„´ ì‚¬ìš©
        keyword = search_keywords[0]
        search_patterns = [
            f"%{keyword}%",  # ê¸°ë³¸ íŒ¨í„´
        ]
        
        # GPU ëª¨ë¸ íŒ¨í„´ ê°œì„  (ì˜ˆ: RX 7900)
        if any(gpu_brand in keyword.upper() for gpu_brand in ["RTX", "GTX", "RX"]):
            # ë¸Œëœë“œì™€ ëª¨ë¸ ë²ˆí˜¸ ë¶„ë¦¬ ì‹œë„
            gpu_pattern = re.search(r'(RTX|GTX|RX)\s*(\d{3,4})(\s*Ti)?', keyword, re.IGNORECASE)
            if gpu_pattern:
                brand = gpu_pattern.group(1)
                model = gpu_pattern.group(2)
                search_patterns.extend([
                    f"%{brand}%{model}%",       # RX 7900
                    f"%ë¼ë°ì˜¨%{brand}%{model}%", # ë¼ë°ì˜¨ RX 7900
                    f"%{model}%",               # 7900ë§Œ
                ])
        
        # CPU ëª¨ë¸ íŒ¨í„´ ê°œì„  (ì˜ˆ: 5600X)
        if "cpu" in part_types:
            cpu_pattern = re.search(r'(\d{4})(\s*[Xx]\d?)?', keyword, re.IGNORECASE)
            if cpu_pattern:
                model = cpu_pattern.group(1)
                suffix = cpu_pattern.group(2) or ""
                suffix = suffix.strip()
                search_patterns.extend([
                    f"%{model}{suffix}%",      # 5600X
                    f"%ë¼ì´ì  %{model}{suffix}%", # ë¼ì´ì   5600X
                    f"%RYZEN%{model}{suffix}%", # RYZEN 5600X
                ])
        
        # ê´€ê³„ ë§¤í•‘
        relations = []
        
        # ëª¨ë“  ê°€ëŠ¥í•œ ë¶€í’ˆ ê°„ ê´€ê³„ ì •ì˜ - GPU-ë©”ì¸ë³´ë“œ í˜¸í™˜ì„± ìš°ì„ ìˆœìœ„ ë‚®ì¶¤
        compatibility_relations = {
            # GPU ê´€ë ¨ í˜¸í™˜ì„± - ì¼€ì´ìŠ¤ì™€ ì „ì› ìš°ì„ 
            ("gpu", "case_chassis"): "gpu_case",
            ("gpu", "power_supply"): "gpu_psu",
            # GPU-ë©”ì¸ë³´ë“œ í˜¸í™˜ì„±ì€ ëŒ€ë¶€ë¶„ PCIeë¡œ í•´ê²°ë˜ë¯€ë¡œ ìš°ì„ ìˆœìœ„ ë‚®ì¶¤
            ("gpu", "motherboard"): "gpu_motherboard",
            
            # ë‹¤ë¥¸ í˜¸í™˜ì„± ê´€ê³„
            ("cpu", "motherboard"): "cpu_motherboard",
            ("cpu", "cpu_cooler"): "cpu_cooler",
            ("motherboard", "case_chassis"): "motherboard_case",
            ("motherboard", "memory"): "motherboard_memory",
            ("motherboard", "storage"): "motherboard_storage",
            ("power_supply", "case_chassis"): "psu_case",
            ("cpu_cooler", "case_chassis"): "cooler_case"
        }
        
        # ì–¸ê¸‰ëœ ë¶€í’ˆ íƒ€ì… ê°„ì˜ ëª¨ë“  ê°€ëŠ¥í•œ í˜¸í™˜ì„± ê´€ê³„ ì¶”ê°€
        for i, type1 in enumerate(part_types):
            for type2 in part_types[i+1:]:
                relation_key = tuple(sorted([type1, type2]))
                if relation_key in compatibility_relations or (relation_key[1], relation_key[0]) in compatibility_relations:
                    if relation_key in compatibility_relations:
                        relations.append(compatibility_relations[relation_key])
                    else:
                        relations.append(compatibility_relations[(relation_key[1], relation_key[0])])
        
        # ë¶€í’ˆ íƒ€ì…ì´ ìˆì§€ë§Œ ê´€ê³„ê°€ ì—†ëŠ” ê²½ìš°, ì£¼ìš” í˜¸í™˜ì„± ê´€ê³„ ì¶”ê°€
        if part_types and not relations:
            primary_part = part_types[0]
            if primary_part == "gpu":
                # GPUì˜ ê²½ìš° ì¼€ì´ìŠ¤ ë° ì „ì› í˜¸í™˜ì„±ì„ ìš°ì„ ì‹œ
                relations.append("gpu_case")
                relations.append("gpu_psu")
                # ë©”ì¸ë³´ë“œ í˜¸í™˜ì„±ì€ ë§ˆì§€ë§‰ì— ì¶”ê°€
                relations.append("gpu_motherboard")
            elif primary_part == "cpu":
                relations.append("cpu_motherboard")
                relations.append("cpu_cooler")
            elif primary_part == "motherboard":
                relations.append("motherboard_case")
                relations.append("motherboard_memory")
                relations.append("motherboard_storage")
            elif primary_part == "power_supply":
                relations.append("psu_case")
        
        # ê´€ê³„ê°€ ì—¬ì „íˆ ì—†ëŠ” ê²½ìš°, í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •
        if not relations:
            # GPU í‚¤ì›Œë“œ í™•ì¸
            if any(kw in keyword.upper() for kw in ["RTX", "GTX", "RX", "RADEON", "GEFORCE"]):
                # GPUì˜ ê²½ìš° ì¼€ì´ìŠ¤ ë° ì „ì› í˜¸í™˜ì„±ì„ ìš°ì„ ì‹œ
                relations.append("gpu_case")
                relations.append("gpu_psu")
                # ë©”ì¸ë³´ë“œ í˜¸í™˜ì„±ì€ ë§ˆì§€ë§‰ì— ì¶”ê°€
                relations.append("gpu_motherboard")
            # CPU í‚¤ì›Œë“œ í™•ì¸
            elif any(kw in keyword.upper() for kw in ["RYZEN", "INTEL", "CORE", "I7", "I9", "5800X", "7800X"]):
                relations.append("cpu_motherboard")
                relations.append("cpu_cooler")
            # ë©”ëª¨ë¦¬ í‚¤ì›Œë“œ í™•ì¸
            elif any(kw in keyword.upper() for kw in ["DDR4", "DDR5", "RAM", "GB", "VENGEANCE", "DOMINATOR"]):
                relations.append("motherboard_memory")
        
        # SQL ì¿¼ë¦¬ ìƒì„±
        queries = {}
        
        # í…Œì´ë¸”ê³¼ ì¿¼ë¦¬ ë§¤í•‘ì„ ëª…í™•íˆ ì •ì˜
        query_templates = {
            # GPUì™€ ì¼€ì´ìŠ¤ í˜¸í™˜ì„± (ìˆ˜ì •ë¨)
            "gpu_case": """
                WITH RankedCases AS (
                    SELECT 
                        g.model_name AS gpu_model, 
                        g.length AS gpu_length, 
                        c.model_name AS case_model,
                        c.vga_length AS available_gpu_length,
                        g.manufacturer AS gpu_manufacturer,
                        c.manufacturer AS case_manufacturer,
                        (c.vga_length - g.length) AS space_difference,
                        ROW_NUMBER() OVER (PARTITION BY g.model_name ORDER BY (c.vga_length - g.length)) AS rank
                    FROM 
                        gpu g, case_chassis c
                    WHERE 
                        g.model_name LIKE '%{pattern}%' 
                        AND g.length <= c.vga_length
                )
                SELECT 
                    gpu_model, 
                    gpu_length, 
                    case_model,
                    available_gpu_length,
                    gpu_manufacturer,
                    case_manufacturer,
                    space_difference
                FROM 
                    RankedCases
                WHERE 
                    rank = 1
                ORDER BY 
                    CASE WHEN gpu_model LIKE '%Ti%' THEN 1 ELSE 0 END,
                    gpu_model
                LIMIT 10
            """,
            
            # GPUì™€ ì „ì› í˜¸í™˜ì„± (ìˆ˜ì •ë¨)
            "gpu_psu": """
                SELECT 
                    g.model_name AS gpu_model, 
                    g.power_consumption AS gpu_power,
                    p.model_name AS psu_model,
                    p.wattage AS psu_wattage,
                    g.manufacturer AS gpu_manufacturer,
                    p.manufacturer AS psu_manufacturer
                FROM 
                    gpu g, power_supply p
                WHERE 
                    g.model_name LIKE '{pattern}' 
                    AND g.power_consumption <= (p.wattage * 0.7)
                LIMIT 10
            """,
            
            # CPUì™€ ë©”ì¸ë³´ë“œ í˜¸í™˜ì„± (ìˆ˜ì •ë¨)
            "cpu_motherboard": """
                SELECT 
                    c.model_name AS cpu_model, 
                    c.socket_type AS cpu_socket, 
                    m.model_name AS motherboard_model,
                    m.socket_type AS mb_socket,
                    c.manufacturer AS cpu_manufacturer,
                    m.manufacturer AS mb_manufacturer
                FROM 
                    cpu c, motherboard m
                WHERE 
                    (c.model_name LIKE '{pattern}' OR c.socket_type = '{pattern}')
                    AND c.socket_type = m.socket_type
                LIMIT 10
            """,
            
            # ë©”ì¸ë³´ë“œì™€ ì¼€ì´ìŠ¤ í˜¸í™˜ì„± (ìˆ˜ì •ë¨)
            "motherboard_case": """
                SELECT 
                    m.model_name AS motherboard_model, 
                    m.form_factor AS mb_form_factor, 
                    c.model_name AS case_model,
                    c.supported_mb_types AS case_supported_mb_types,
                    m.manufacturer AS mb_manufacturer,
                    c.manufacturer AS case_manufacturer
                FROM 
                    motherboard m, case_chassis c
                WHERE 
                    m.model_name LIKE '{pattern}'
                    AND (
                        (m.form_factor = 'ATX' AND c.supported_mb_types LIKE '%ATX%') OR
                        (m.form_factor = 'mATX' AND c.supported_mb_types LIKE '%mATX%') OR
                        (m.form_factor = 'ITX' AND c.supported_mb_types LIKE '%ITX%')
                    )
                LIMIT 10
            """,
            
            # ê¸°ë³¸ ì¿¼ë¦¬ í…œí”Œë¦¿ (ë³€ê²½ ì—†ìŒ)
            "default": """
                SELECT * FROM {table_name} 
                WHERE model_name LIKE '{pattern}'
                LIMIT 10
            """
        }

        
        # ê° ê´€ê³„ì— ëŒ€í•œ ì¿¼ë¦¬ ìƒì„±
        for relation in relations:
            # ê° ê²€ìƒ‰ íŒ¨í„´ì— ëŒ€í•´ ì‹œë„
            query = None
            for pattern in search_patterns:
                # ì¿¼ë¦¬ í…œí”Œë¦¿ ì„ íƒ
                if relation in query_templates:
                    query = query_templates[relation].format(pattern=pattern)
                else:
                    # ê´€ê³„ì— í•´ë‹¹í•˜ëŠ” í…Œì´ë¸” ì°¾ê¸°
                    table_name = relation
                    # ë§¤í•‘ëœ í…Œì´ë¸” ì´ë¦„ í™•ì¸
                    if table_name in table_mapping:
                        table_name = table_mapping[table_name]
                    
                    # í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                    if table_name in db_schema:
                        query = query_templates["default"].format(
                            table_name=table_name,
                            pattern=pattern
                        )
                    else:
                        # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ë‹¤ìŒ íŒ¨í„´ìœ¼ë¡œ ë„˜ì–´ê°
                        continue
                
                # ì¿¼ë¦¬ê°€ ìƒì„±ë˜ì—ˆìœ¼ë©´ ì €ì¥í•˜ê³  ë£¨í”„ ì¢…ë£Œ
                if query:
                    queries[relation] = query
                    logger.debug(f"ìƒì„±ëœ SQL ì¿¼ë¦¬ ({relation}): \n{query}")
                    break
        
        logger.info(f"ìƒì„±ëœ ì¿¼ë¦¬ ê´€ê³„: {list(queries.keys())}")
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["queries"] = queries
        
        logger.debug(f"Node generate_queries completed")
        return state
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        state["errors"].append(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return state

# ì¿¼ë¦¬ ìµœì í™” í•¨ìˆ˜ ê°œì„ 
def optimize_search_query(state: PCCompatibilityState) -> PCCompatibilityState:
    """SQL ì¿¼ë¦¬ë¥¼ ìµœì í™”í•˜ê³  ë°ì´í„°ë² ì´ìŠ¤ì— ë§ê²Œ ì¡°ì •"""
    logger.info("Starting node: optimize_search_query")
    
    part_types = state["part_types"]
    queries = state["queries"]
    search_keywords = state["search_keywords"]
    
    # í•¨ìˆ˜ ì‹œì‘ì‹œ ìƒíƒœ ë¡œê¹…
    logger.debug(f"===== STATE (optimize_search_query_start) =====")
    logger.debug(f"part_types: {part_types}")
    logger.debug(f"queries: {queries}")
    logger.debug(f"search_keywords: {search_keywords}")
    
    # ì¿¼ë¦¬ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
    if not queries:
        state["errors"].append("No queries generated.")
        return state
    
    # ìµœì í™”ëœ ì¿¼ë¦¬ ì €ì¥
    optimized_queries = {}
    errors = []
    
    # LLMì„ ì´ìš©í•œ ì¿¼ë¦¬ ìµœì í™”
    for relation, query in queries.items():
        try:
            # ì´ë¯¸ ì¿¼ë¦¬ê°€ ì˜ êµ¬ì„±ë˜ì–´ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            optimized_queries[relation] = query
            logger.debug(f"ìµœì í™” ì¿¼ë¦¬ ({relation}):\n{query}")
        except Exception as e:
            error_msg = f"ì¿¼ë¦¬ ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            errors.append(error_msg)
            logger.warning(error_msg)
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["queries"] = optimized_queries
    if errors:
        state["errors"].extend(errors)
    
    # ë¡œê¹…
    if optimized_queries:
        logger.info(f"Identified part types: {part_types}")
        logger.info(f"Extracted keywords: {search_keywords}")
        logger.info(f"Generated {len(optimized_queries)} queries for relations: {list(optimized_queries.keys())}")
    
    if errors:
        logger.warning(f"Errors encountered: {errors}")
    
    # í•¨ìˆ˜ ì¢…ë£Œì‹œ ìƒíƒœ ë¡œê¹…
    logger.debug(f"Node optimize_search_query completed")
    return state

# ì¿¼ë¦¬ ì‹¤í–‰ í•¨ìˆ˜ ê°œì„ 
def execute_queries(state: PCCompatibilityState) -> PCCompatibilityState:
    """SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° ê²°ê³¼ ì²˜ë¦¬"""
    logger.info("Starting node: execute_queries")
    
    queries = state["queries"]
    
    # í•¨ìˆ˜ ì‹œì‘ì‹œ ìƒíƒœ ë¡œê¹…
    logger.debug(f"===== STATE (execute_queries_start) =====")
    logger.debug(f"ì‹¤í–‰í•  ì¿¼ë¦¬: {list(queries.keys())}")
    
    results = {}
    errors = []
    
    # ê²°ê³¼ê°€ ì¶©ë¶„í•œì§€ í™•ì¸í•˜ëŠ” ì„ê³„ê°’
    SUFFICIENT_RESULTS = 5
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    try:
        with duckdb.connect(database=DB_PATH, read_only=True) as conn:
            for relation, query in queries.items():
                try:
                    logger.debug(f"===== ì¿¼ë¦¬ ì‹¤í–‰ ({relation}) =====")
                    logger.debug(f"SQL:\n{query}")
                    
                    # ì¿¼ë¦¬ ì‹¤í–‰
                    df = conn.execute(query).fetchdf()
                    
                    # ê²°ê³¼ ë³€í™˜
                    if not df.empty:
                        records = df.to_dict('records')
                        results[relation] = records
                        logger.debug(f"ì¿¼ë¦¬ ê²°ê³¼ ({relation}): {len(records)} ê°œ ë ˆì½”ë“œ")
                        
                        # ì²˜ìŒ ëª‡ ê°œ ê²°ê³¼ ìƒ˜í”Œ ë¡œê¹…
                        for i, record in enumerate(records[:3]):
                            logger.debug(f"  ê²°ê³¼ {i+1}: {record}")
                    else:
                        logger.debug(f"ì¿¼ë¦¬ ê²°ê³¼ ({relation}): ê²°ê³¼ ì—†ìŒ")
                        
                except Exception as e:
                    error_msg = f"Error executing query for {relation}: {str(e)}"
                    errors.append(error_msg)
                    logger.error(error_msg)
                    logger.exception(f"ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ ({relation})")
    except Exception as e:
        error_msg = f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {str(e)}"
        errors.append(error_msg)
        logger.error(error_msg)
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["results"] = results
    if errors:
        state["errors"].extend(errors)
    
    # í•¨ìˆ˜ ì¢…ë£Œì‹œ ìƒíƒœ ë¡œê¹…
    logger.debug(f"Node execute_queries completed")
    return state

# 4. ê²°ê³¼ ì„¤ëª… ìƒì„± ë…¸ë“œ
def generate_explanation(state: PCCompatibilityState) -> PCCompatibilityState:
    """ê²°ê³¼ í†µí•© ë° ìƒì„¸í•œ ì¶”ì²œ PC êµ¬ì„± ì„¤ëª… ìƒì„± (ì¶”ì²œ êµ¬ì„± ìë™ ìƒì„± ì¶”ê°€)"""
    logger.info("Starting node: generate_explanation")
    
    question = state["question"]
    results = state["results"]
    errors = state["errors"]
    search_keywords = state["search_keywords"]
    part_types = state["part_types"]
    
    # ìƒíƒœ ë¡œê¹…
    logger.debug(f"===== STATE (generate_explanation_start) =====")
    
    # ì‹¤ì œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ì‹ëœ ëª¨ë¸ í™•ì¸
    recognized_models = {}
    for keyword in search_keywords:
        if "gpu" in part_types and any(gpu_term in keyword.lower() for gpu_term in ["rtx", "rx", "geforce", "radeon"]):
            recognized_models["gpu"] = keyword
        elif "cpu" in part_types and any(cpu_term in keyword.lower() for cpu_term in ["ryzen", "core", "intel", "amd"]):
            recognized_models["cpu"] = keyword
    
    # ì¶”ì²œ êµ¬ì„± ìë™ ìƒì„±: ê° ë¶€í’ˆë³„ í›„ë³´ë¥¼ ì¿¼ë¦¬ ê²°ê³¼ì—ì„œ ì¶”ì¶œ
    recommended_config = {}
    
    # GPU ë° ì¼€ì´ìŠ¤: gpu_case ì¿¼ë¦¬ ê²°ê³¼ í™œìš©
    if "gpu_case" in results and results["gpu_case"]:
        first_row = results["gpu_case"][0]
        recommended_config["GPU"] = first_row.get("gpu_model", recognized_models.get("gpu", "ì í•©í•œ GPU"))
        recommended_config["ì¼€ì´ìŠ¤"] = first_row.get("case_model", "ì í•©í•œ ì¼€ì´ìŠ¤")
        
        # ê³µê°„ íš¨ìœ¨ì„± ì •ë³´ ì¶”ê°€
        space_diff = first_row.get("space_difference")
        if space_diff is not None and space_diff > 0:
            recommended_config["ì¼€ì´ìŠ¤ ì—¬ìœ  ê³µê°„"] = f"{space_diff}mm"
    else:
        recommended_config["GPU"] = recognized_models.get("gpu", "ì í•©í•œ GPU")
        recommended_config["ì¼€ì´ìŠ¤"] = "ì í•©í•œ ì¼€ì´ìŠ¤ (GPU ê¸¸ì´ í™•ì¸ í•„ìš”)"

    # CPUì™€ ë©”ì¸ë³´ë“œ: cpu_motherboard ê²°ê³¼ í™œìš©
    if "cpu_motherboard" in results and results["cpu_motherboard"]:
        first_row = results["cpu_motherboard"][0]
        recommended_config["CPU"] = recognized_models.get("cpu", "ì í•©í•œ CPU")
        recommended_config["ë©”ì¸ë³´ë“œ"] = first_row.get("motherboard_model", "í˜¸í™˜ë˜ëŠ” ë©”ì¸ë³´ë“œ")
    elif "motherboard_case" in results and results["motherboard_case"]:
        first_row = results["motherboard_case"][0]
        recommended_config["CPU"] = recognized_models.get("cpu", "ì í•©í•œ CPU")
        recommended_config["ë©”ì¸ë³´ë“œ"] = first_row.get("motherboard_model", "í˜¸í™˜ë˜ëŠ” ë©”ì¸ë³´ë“œ")
    else:
        recommended_config["CPU"] = recognized_models.get("cpu", "ì í•©í•œ CPU")
        recommended_config["ë©”ì¸ë³´ë“œ"] = "í˜¸í™˜ë˜ëŠ” ë©”ì¸ë³´ë“œ"

    # PSU: gpu_psu ê²°ê³¼ í™œìš©
    if "gpu_psu" in results and results["gpu_psu"]:
        first_row = results["gpu_psu"][0]
        recommended_config["PSU"] = first_row.get("psu_model", "ì¶©ë¶„í•œ ìš©ëŸ‰ì˜ PSU")
    else:
        recommended_config["PSU"] = "ì¶©ë¶„í•œ ìš©ëŸ‰ì˜ PSU"
    
    # CPU ì¿¨ëŸ¬: cpu_cooler ê²°ê³¼ í™œìš© (ì»¬ëŸ¼ ì´ë¦„: cooler_model)
    if "cpu_cooler" in results and results["cpu_cooler"]:
        first_row = results["cpu_cooler"][0]
        recommended_config["CPU ì¿¨ëŸ¬"] = first_row.get("cooler_model", "")
    # (ì—†ìœ¼ë©´ ì„ íƒí•˜ì§€ ì•ŠìŒ)
    
    # ìš”ì•½ ë°ì´í„°ì— ì¶”ì²œ êµ¬ì„± í¬í•¨
    summary = {
        "ì¶”ì²œêµ¬ì„±": recommended_config
    }
    
    # ì¿¼ë¦¬ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    results_str = ""
    if not results:
        results_str = "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜¸í™˜ì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    else:
        for relation, result in results.items():
            relation_kr = relation.replace("gpu_motherboard", "GPUì™€ ë©”ì¸ë³´ë“œ")
            relation_kr = relation_kr.replace("gpu_case", "GPUì™€ ì¼€ì´ìŠ¤")
            relation_kr = relation_kr.replace("cpu_motherboard", "CPUì™€ ë©”ì¸ë³´ë“œ")
            relation_kr = relation_kr.replace("motherboard_case", "ë©”ì¸ë³´ë“œì™€ ì¼€ì´ìŠ¤")
            
            results_str += f"{relation_kr} í˜¸í™˜ì„±:\n"
            if result:
                for item in result[:10]:
                    results_str += f"- {', '.join([f'{k}: {v}' for k, v in item.items()])}\n"
                if len(result) > 10:
                    results_str += f"... ê·¸ë¦¬ê³  {len(result) - 10}ê°œ ë” ìˆìŒ\n"
            else:
                results_str += "í˜¸í™˜ë˜ëŠ” ë¶€í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            results_str += "\n"
    
    errors_str = "\n".join(errors) if errors else "ì˜¤ë¥˜ ì—†ìŒ."
    search_keywords_str = ", ".join(search_keywords) if search_keywords else "ì¸ì‹ëœ í‚¤ì›Œë“œ ì—†ìŒ"
    
    # ì¶”ì²œ êµ¬ì„± ë¬¸ìì—´ ìƒì„±
    recommended_config_str = "ì¶”ì²œ PC êµ¬ì„±:\n"
    for comp, model in recommended_config.items():
        recommended_config_str += f"- {comp}: {model}\n"
    
    # ê°œì„ ëœ LLM í”„ë¡¬í”„íŠ¸ (í˜¸í™˜ì„± ê²°ê³¼ì™€ ì¶”ì²œ êµ¬ì„±ì„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨)
    explanation_prompt = f"""
    ë‹¹ì‹ ì€ PC í•˜ë“œì›¨ì–´ í˜¸í™˜ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ í˜¸í™˜ì„± ê²°ê³¼ì™€ ì¶”ì²œ PC êµ¬ì„±ì„ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
    
    ì‚¬ìš©ì ì§ˆë¬¸: {question}
    ì‹¤ì œ ê²€ìƒ‰í•œ í‚¤ì›Œë“œ: {search_keywords_str}
    ë¶„ì„ëœ ë¶€í’ˆ ìœ í˜•: {part_types}
    
    --- í˜¸í™˜ì„± ê²°ê³¼ ---
    {results_str}
    
    --- ì¶”ì²œ PC êµ¬ì„± ---
    {recommended_config_str}
    
    --- ì˜¤ë¥˜ ---
    {errors_str}
    
    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”:
    1. ìš”ì•½: í˜¸í™˜ì„± ê²°ê³¼ì™€ ì¶”ì²œ êµ¬ì„±ì— ëŒ€í•´ ê°„ê²°íˆ ìš”ì•½.
    2. ì¶”ì²œ PC êµ¬ì„±: ê° ë¶€í’ˆ(ì˜ˆ: GPU, CPU, ë©”ì¸ë³´ë“œ, ì¼€ì´ìŠ¤, PSU ë“±)ì˜ êµ¬ì²´ì ì¸ ëª¨ë¸ëª…ì„ ì¶”ì²œí•˜ê³ , ì„ íƒí•œ ì´ìœ ë¥¼ ì„¤ëª….
    3. ë°ì´í„° ë¶€ì¡± ì‹œ ì£¼ì˜ì‚¬í•­ì„ ëª…ì‹œí•  ê²ƒ.
    
    ì„¤ëª…:
    """
    
    explanation = llm.invoke(explanation_prompt)
    
    # ë¡œê¹…
    logger.debug(f"====== LLM PROMPT (generate_explanation) ======")
    logger.debug(explanation_prompt)
    logger.debug(f"====== LLM RESPONSE (generate_explanation) ======")
    logger.debug(explanation)
    logger.debug(f"====== END LLM CALL (generate_explanation) ======")
    
    final_result = {
        "summary": summary,
        "recommended_config": recommended_config,
        "detailed_results": results,
        "explanation": explanation,
        "errors": errors
    }
    
    state["final_result"] = final_result
    logger.debug(f"Node generate_explanation completed")
    return state

# ìƒíƒœ íë¦„ ê·¸ë˜í”„ êµ¬ì¶• - ë¡œê¹… ì¶”ê°€
def build_graph():
    """LangGraph ê·¸ë˜í”„ ë¹Œë“œ"""
    logger.info("PC í˜¸í™˜ì„± ê²€ì‚¬ ê·¸ë˜í”„ êµ¬ì¶• ì‹œì‘")
    
    # ë¡œê¹…ê³¼ í•¨ê»˜ ë…¸ë“œ ì¶”ê°€í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def add_node_with_logging(name, func):
        def logged_func(state):
            logger.info(f"Starting node: {name}")
            try:
                result = func(state)
                # ìƒíƒœ ë¡œê¹…ì„ ì¶•ì†Œí•˜ê³  ì¤‘ìš”í•œ ì •ë³´ë§Œ ë¡œê¹…
                logger.debug(f"Node {name} completed")
                return result
            except Exception as e:
                logger.error(f"Error in node {name}: {str(e)}")
                raise
        graph.add_node(name, logged_func)
    
    # ê·¸ë˜í”„ ìƒì„±
    graph = StateGraph(PCCompatibilityState)
    
    # ë…¸ë“œ ì¶”ê°€
    add_node_with_logging("analyze_question", analyze_question)
    add_node_with_logging("generate_queries", generate_queries)
    add_node_with_logging("optimize_search_query", optimize_search_query)
    add_node_with_logging("execute_queries", execute_queries)
    add_node_with_logging("generate_explanation", generate_explanation)
    
    # ì—£ì§€ ì¶”ê°€
    graph.add_edge("analyze_question", "generate_queries")
    graph.add_edge("generate_queries", "optimize_search_query")
    graph.add_edge("optimize_search_query", "execute_queries")
    graph.add_edge("execute_queries", "generate_explanation")
    graph.add_edge("generate_explanation", END)
    
    # ì‹œì‘ ë…¸ë“œ ì„¤ì •
    graph.set_entry_point("analyze_question")
    
    logger.info("PC í˜¸í™˜ì„± ê²€ì‚¬ ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ")
    
    # ì»´íŒŒì¼ ë° ë°˜í™˜
    return graph.compile()

# ê·¸ë˜í”„ êµ¬ì¶•
pc_compatibility_graph = build_graph()

# Function callingì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜
def process_pc_compatibility_query(question, input_state=None):
    """PC í˜¸í™˜ì„± í™•ì¸ í•¨ìˆ˜ - ì…ë ¥ ìƒíƒœ ì§ì ‘ ìˆ˜ì‹  ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •"""
    logger.info(f"PC í˜¸í™˜ì„± ì¿¼ë¦¬ ì²˜ë¦¬: {question}")
    
    # ê¸°ë³¸ ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "question": question,
        "search_keywords": [],
        "pc_parts": {},
        "compatibility_issues": [],
        "performance_estimates": {},
        "explanation": "",
        "errors": [],
        "collected_information": []
    }
    
    # ì…ë ¥ ìƒíƒœê°€ ì œê³µëœ ê²½ìš° ë³‘í•©
    if input_state:
        for key, value in input_state.items():
            initial_state[key] = value
    
    # ê·¸ë˜í”„ ì‹¤í–‰
    final_state = pc_compatibility_graph.invoke(initial_state)
    
    # ìµœì¢… ê²°ê³¼ ë°˜í™˜
    if final_state["final_result"]:
        return final_state["final_result"]
    else:
        return {
            "explanation": "ì§ˆë¬¸ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            "errors": final_state["errors"]
        }


# # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
# test_query = "RTX 3080ì´ë‘ í˜¸í™˜ë˜ëŠ” ë©”ì¸ë³´ë“œë‘ ì¼€ì´ìŠ¤ ì•Œë ¤ì¤˜ CPUëŠ” 5600x ì‚¬ìš©í•˜ê³ ì‹¶ì–´"
# test_query = "RTX 3080 ì œí’ˆ ìŠ¤í™ì„ ìì„¸íˆ ì•Œê³ ì‹¶ì–´"

# í•¨ìˆ˜ í˜¸ì¶œ
# result = process_pc_compatibility_query(test_query)

# ê²°ê³¼ ì¶œë ¥
# print("\nExplanation:")
# print(result["explanation"])